{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63ac74b-ec5e-4e7e-912d-5db8bd7a59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "050ab220-d1b4-40bb-b2d5-0d93b7a9a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, img_channel, img_height, img_width, num_classes,\n",
    "                 leaky_relu = True, map_to_sequence = 64, lstm_hidden = 256):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn, dimension = self._create_cnn(img_channel, img_height, img_width, leaky_relu)\n",
    "        output_channel, output_height, output_width = dimension\n",
    "        \n",
    "        self.map_2_sequence = nn.Linear(output_channel * output_height, map_to_sequence)\n",
    "        self.lstm1 = nn.LSTM(map_to_sequence, lstm_hidden, \n",
    "                             bidirectional = True, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(2 * lstm_hidden, lstm_hidden,\n",
    "                             bidirectional = True, batch_first = True)\n",
    "\n",
    "        self.dense = nn.Linear(2 * lstm_hidden, num_classes)\n",
    "        \n",
    "    def _create_cnn(self, img_channel, img_height, img_width, leaky_relu):\n",
    "        assert img_height % 16 == 0\n",
    "        assert img_width % 4 == 0\n",
    "\n",
    "        # m means the mode: 0 is convolution, 1 is max pooling\n",
    "        # k means kernel_size\n",
    "        # s means stride\n",
    "        # p means padding\n",
    "        cfgs = [\n",
    "            #m   #k,     #s    #p    #c    #bn\n",
    "            [0,  (3, 3),  1,   1,    64,  False],\n",
    "            [1,  (2, 2),  2,   None, None, False],\n",
    "            [0,  (3, 3),  1,   1,    128, False],\n",
    "            [1,  (2, 2),  2,   None, None, False],\n",
    "            [0,  (3, 3),  1,   1,    256,  False],\n",
    "            [0,  (3, 3),  1,   1,    256,  False],\n",
    "            [1,  (2, 1),  2,   None,  None, False],\n",
    "            [0,  (3, 3),  1,   1,    512,   True],\n",
    "            [0,  (3, 3),  1,   1,    512,   True],\n",
    "            [1,  (2, 1),  2,   None,  None, False],\n",
    "            [0,  (2, 2),  1,   1,    512,   True],\n",
    "        ]\n",
    "\n",
    "        cnn = []\n",
    "        input_channels = img_channel\n",
    "        output_channels = None\n",
    "        \n",
    "        for m, k, s, p, c, bn in cfgs:\n",
    "            if m == 0: # Convolution \n",
    "                output_channels = c\n",
    "                \n",
    "                cnn.append(nn.Conv2d(input_channels, output_channels, \n",
    "                                     kernel_size = k, stride = s, \n",
    "                                     padding = p))\n",
    "                relu = nn.LeakyReLU(0.2, inplace = True) if leaky_relu == True \\\n",
    "                            else nn.ReLU(inplace = True)\n",
    "                cnn.append(relu)\n",
    "                \n",
    "                if bn == True:\n",
    "                    cnn.append(nn.BatchNorm2d(output_channels))\n",
    "                           \n",
    "                input_channels = output_channels\n",
    "                \n",
    "            elif m == 1:\n",
    "                cnn.append(nn.MaxPool2d(kernel_size = k, stride = s))\n",
    "\n",
    "        cnn_module = nn.Sequential(*cnn)\n",
    "        # The output height and width of an image after passing through CNN\n",
    "        output_height = img_height // 16 - 1 \n",
    "        output_width = img_width // 4 - 1\n",
    "        \n",
    "        return cnn_module, (output_channels, output_height, output_width)\n",
    "\n",
    "    def forward(self, image):\n",
    "        conv = self.conv(image)\n",
    "        batch, channel, height, width = conv.size()\n",
    "\n",
    "        conv = conv.view(batch, channel * height, width)\n",
    "        conv = conv.permute(0, 2, 1)  # (batch, width, channel * height)\n",
    "        seq = self.map_2_sequence(conv)\n",
    "\n",
    "        recurrent, _ = self.lstm1(seq)\n",
    "        recurrent, _ = self.lstm2(recurrent)\n",
    "\n",
    "        logits = self.dense(recurrent)\n",
    "\n",
    "        return F.log_softmax(logits, dim = 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98ec2a0-9e80-4465-94bb-aafbb2a7234d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=(2, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=(2, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (20): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (map_2_sequence): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (lstm1): LSTM(64, 256, batch_first=True, bidirectional=True)\n",
       "  (lstm2): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  (dense): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn = CRNN(1, 32, 100, 100)\n",
    "crnn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e642208c-1a68-4c25-8ed4-b6e63d76ee2c",
   "metadata": {},
   "source": [
    "# CTC Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1e7952-850a-4e5a-a36f-1a7912acb017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "\n",
    "class Hypothesis:\n",
    "    def __init__(self, sequence, log_prob):\n",
    "        self.sequence = sequence\n",
    "        self.log_prob = log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bb5fc3-85ad-4e9c-8e59-f91f91151ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequence:  b b c\n",
      "-1.62964061975162\n"
     ]
    }
   ],
   "source": [
    "def beam_search_decode(probabilities, alphabet, beam_width):\n",
    "    initial_hypothesis = Hypothesis(sequence = [], log_prob = 0.0)\n",
    "    beam = [initial_hypothesis]\n",
    "\n",
    "    for timestep in range(len(probabilities)):\n",
    "        new_beam = []\n",
    "\n",
    "        for hypothesis in beam:\n",
    "            # for label, prob in enumerate(probabilities[timestep]):\n",
    "            #     extended_sequence = hypothesis.sequence + [alphabet[label]]\n",
    "            #     log_prob = hypothesis.log_prob + math.log(prob)\n",
    "\n",
    "            #     new_hypothesis = Hypothesis(sequence = extended_sequence,\n",
    "            #                                 log_prob = log_prob)\n",
    "            #     new_beam.append(new_hypothesis)\n",
    "\n",
    "            for c in range(probabilities.shape[1]):\n",
    "                extended_sequence = hypothesis.sequence + [alphabet[c]]\n",
    "                log_prob = hypothesis.log_prob + math.log(probabilities[timestep, c])\n",
    "                new_hypothesis = Hypothesis(sequence = extended_sequence,\n",
    "                                            log_prob = log_prob)\n",
    "                new_beam.append(new_hypothesis)\n",
    "        # Select top-k hypothesis\n",
    "        beam = sorted(new_beam, key = lambda x: x.log_prob, reverse = True)[:beam_width]\n",
    "\n",
    "    # Select the best hypothesis from the final beam\n",
    "    best_sequence = max(beam, key = lambda x: x.log_prob)\n",
    "\n",
    "    # Select the best hypothesis \n",
    "    return best_sequence\n",
    "    \n",
    "\n",
    "alphabet = ['a', 'b', 'c']\n",
    "probabilities = np.array([\n",
    "    [0.2, 0.7, 0.1],  # Timestep 1\n",
    "    [0.3, 0.4, 0.3],  # Timestep 2\n",
    "    [0.1, 0.2, 0.7]   # Timestep 3\n",
    "])\n",
    "\n",
    "decoded_sequence = beam_search_decode(probabilities, alphabet, beam_width = 2)\n",
    "print(\"Decoded sequence: \", ' '.join(decoded_sequence.sequence))\n",
    "print(decoded_sequence.log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cb629b-00f1-4047-991f-0724446cb9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.62964061975162"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.7) + math.log(0.4) + math.log(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f6c0c3-9792-4b0a-bbf8-e489606e47b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(probabilities, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdac3a2-f21f-447b-bc31-1b34658197a2",
   "metadata": {},
   "source": [
    "# CTC Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e1418b-257a-435b-b80e-621eeb7540ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target are to be padded\n",
    "\n",
    "T = 50  # Input Sequence Length\n",
    "C = 20  # Number of classes (including blank)\n",
    "N = 16  # Batch size\n",
    "S = 30  # Target sequence Length\n",
    "\n",
    "S_min = 10\n",
    "\n",
    "# Input has size (50, 16, 20)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "\n",
    "# Target has size (16, 30)\n",
    "target = torch.randint(low = 1, high = C, size = (N, S), dtype = torch.long)\n",
    "\n",
    "# Input lengths has size (16)\n",
    "input_lengths = torch.full(size = (N,), fill_value = T, dtype = torch.long)\n",
    "\n",
    "# Target lenths has size (16)\n",
    "target_lengths = torch.randint(low = S_min, high = S, size = (N, ),\n",
    "                                dtype = torch.long)\n",
    "\n",
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32dabae-1e48-4f5a-84ab-67f176b20717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 16, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b24fe4-fecb-4a9f-86cf-d550e755670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2782cbfc-1e0f-4a53-a9bb-f6e3eb523988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa632b0-6148-4825-9420-3f6cc540f9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5691, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a47677-197c-4df5-afc3-9e05dafd8eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2087.9353, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target are to be un-padded\n",
    "T = 50\n",
    "C = 20\n",
    "N = 16\n",
    "\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "input_lengths = torch.full(size = (N, ), fill_value = T, dtype = torch.long)\n",
    "\n",
    "target_lengths = torch.randint(low = 1, high = T, size = (N, ),\n",
    "                                dtype = torch.long)\n",
    "target = torch.randint(low = 1, high = C, size = (sum(target_lengths),), dtype = torch.long)\n",
    "\n",
    "target_lengths\n",
    "\n",
    "ctc_loss = nn.CTCLoss(reduction = 'sum')\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd499c4-fed0-4219-8071-1e1ae7a460d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 16, 20])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98f0a8ad-a839-4b76-8d03-6963499507e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([419])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9abf8e-5574-4106-b614-e0cda24f4e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lengths.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71184157-e3c2-489a-a0c3-9966616f77b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(419)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6a40799-fef0-4300-aed6-fa83f53224e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de061d85-51e1-40f2-b748-a56d0708585e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
